{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://github.com/d9w/evolution/raw/master/imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
    "\n",
    "\n",
    "# Evolutionary Algorithms\n",
    "\n",
    "## NSGA-II\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://supaerodatascience.github.io/stochastic/\">https://d9w.github.io/evolution/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To explore NSGA-II, we'll use the [PyMOO](https://pymoo.org/algorithms/nsga2.html) library and a Multi-Objective Travelling Salesman Problem. For the different objectives, we'll construct random distance matrices, but we could imagine, for example, that one objective is travel time between two points and a second objective is travel cost. We want to minimize both objectives, choosing a route from the Pareto front of quick and low-cost travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we define the Multi-Objective Travelling Salesman Problem using the `ElementwiseProblem` class from `pymoo`. We'll define it to take any number of cities and objectives, returning a fitness of the total distance from each objective for the given individual. We specify a constraint on the order to ensure we're visiting each city once, but we'll also define the same operators as in the GA notebook to make sure all individuals meet this constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "class MOTSP(ElementwiseProblem):\n",
    "    \n",
    "    def __init__(self, n_cities, n_obj):\n",
    "        # lower bound\n",
    "        xl = np.zeros(n_cities)\n",
    "        # upper bound\n",
    "        xu = (n_cities-1) * np.ones(n_cities)\n",
    "        \n",
    "        self.n_cities = n_cities\n",
    "        self.distances = []\n",
    "        for i in range(n_obj):\n",
    "            # random symmetric matrix\n",
    "            d = np.random.rand(n_cities, n_cities)\n",
    "            d = np.tril(d) + np.tril(d, -1).T\n",
    "            d[np.diag_indices(n_cities)] = 0\n",
    "            self.distances.append(d)\n",
    "        \n",
    "        super().__init__(n_var=n_cities, n_obj=n_obj, n_constr=1,\n",
    "                        xl=xl, xu=xu)\n",
    "        \n",
    "    def total_distance(self, x, d):\n",
    "        t = 0\n",
    "        for i in range(1, len(x)):\n",
    "            t += self.distances[d][x[i-1], x[i]]\n",
    "        return t\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        # fitness based on each distance matrix\n",
    "        fits = np.zeros(len(self.distances))\n",
    "        for i in range(len(self.distances)):\n",
    "            fits[i] = self.total_distance(x, i)\n",
    "        \n",
    "        # constraints return negative if met\n",
    "        c = -np.sum(np.arange(self.n_cities) != np.sort(x))\n",
    "        \n",
    "        # return by modifying out\n",
    "        out[\"F\"] = np.column_stack(fits)\n",
    "        out[\"G\"] = np.array([c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, we define NSGA2, its hyperparameters and operators. We'll use the same operators as before. Note that `pymoo` allows for generating fewer offspring than the initial population size and that it can check for duplicates. We'll use this second feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.erx import EdgeRecombinationCrossover\n",
    "from pymoo.operators.sampling.rnd import PermutationRandomSampling\n",
    "from pymoo.operators.mutation.inversion import InversionMutation\n",
    "\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,\n",
    "    n_offsprings=100,\n",
    "    sampling=PermutationRandomSampling(),\n",
    "    crossover=EdgeRecombinationCrossover(),\n",
    "    mutation=InversionMutation(),\n",
    "    eliminate_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To start, let's define a 20-city problem with 2 objectives. As mentioned, these could be total travel time and total travel cost. We want to minimize both objectives. Note the use of `seed=1` in the call to `minimize`: this optimization is deterministic (we can run it multiple times and get the same result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pymoo.optimize import minimize\n",
    "\n",
    "problem = MOTSP(20, 2)\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               (\"n_gen\", 100),\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `res` object returned from the search contains the results, including the final Pareto front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "plot = Scatter(tight_layout=True)\n",
    "plot.add(res.F, s=10)\n",
    "plot.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise 1</h3>\n",
    "\n",
    "Look at the [visualization](http://pymoo.org/visualization/index.html) options in pymoo and visualize the population. What plot makes most sense to you to present the full population of possible solutions? What about presenting a single solution? What about when the number of objectives increases, ie to 5?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also visualize the convergence of each objective. We'll plot the fitness of the first individual in the Pareto front over evolution. Note that this isn't the best value for each objective independently, but rather the objective values of a single individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_evals = np.array([e.evaluator.n_eval for e in res.history])\n",
    "opt = np.array([e.opt[0].F for e in res.history])\n",
    "\n",
    "plt.title(\"Convergence\")\n",
    "plt.plot(n_evals, opt)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As the number of dimensions grows, visualizing the convergence across all objectives becomes difficult. One recently proposed metric known as the \"running metric\" evaluates non-dominated sets from each generation relative to previously recorded sets. This gives an idea of how much the Pareto front has moved in any generation. For visualizing this running metric, each ND set is normalized by the final ND set after a certain number of generations. The difference between intervals then gives an idea if the algorithm is converging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://github.com/d9w/evolution/raw/master/imgs/running_metric.png\">\n",
    "\n",
    "Blank, Julian, and Kalyanmoy Deb. \"A running performance metric and termination criterion for evaluating evolutionary multi-and many-objective optimization algorithms.\" Proc. IEEE World Congr. Comput. Intell.(WCCI). 2020.\n",
    "\n",
    "https://www.egr.msu.edu/~kdeb/papers/c2020003.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pymoo.util.running_metric import RunningMetricAnimation\n",
    "\n",
    "running = RunningMetricAnimation(delta_gen=20,\n",
    "                        n_plots=5,\n",
    "                        key_press=False,\n",
    "                        do_show=True)\n",
    "\n",
    "for algorithm in res.history:\n",
    "    running.update(algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise 2</h3>\n",
    "\n",
    "Increase the number of objectives and observe the convergence of NSGA-II. Roughly, how much does each objective change convergence speed?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
